{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Network Hands-On Tutorial Part 2\n",
    "\n",
    "## MNIST Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the MNIST Dataset\n",
    "\n",
    "`torchvision` provides many built-in datasets, which are common benchmarks and can be used for learning purposes and drafting your own neural network implementations.\n",
    "\n",
    "Run the next cell to download the MNIST dataset and store it to the `./data` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Looking at the Dataset\n",
    "\n",
    "The MNIST train dataset contains 60,000 pairs of data in the shape of (image, label).\n",
    "\n",
    "Each image is a grayscale image cropped to 28*28 pixels, with a centered handwritten digit.\n",
    "\n",
    "_Note_: the test dataset contains 10,000 images with the same shape as the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Looking at the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0  # Change the index to see different images\n",
    "\n",
    "# Show some images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(7, 2.5))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(train_dataset[i+idx][0], cmap='gray')\n",
    "    axes[i].set_title(f\"label: {train_dataset[i+idx][1]}\")\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Looking at the Dataset\n",
    "\n",
    "Currently, the images are `PIL` images and the amplitudes range from 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_dataset[0][0]\n",
    "print(np.max(img), np.min(img), np.shape(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "In order to train a neural network with the dataset, the train dataset needs to be pre-processed. In `PyTorch` and `torchvision`, this can be achieved by `torchvision.transforms`, which includes many common image processing methods.\n",
    "\n",
    "Note that the images in the MNIST dataset are already _centered_ and _cropped to the same shape_. (For your own dataset, remember to perform these steps.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For the MNIST dataset, we only need to perform two steps:\n",
    "\n",
    "1. Convert the PIL images with amplitude $[0,255]$ to PyTorch Tensors in $[0,1]$, with `transforms.ToTensor()`\n",
    "2. Normalize the images to $\\mu=0.5$ and $\\sigma=0.5$, with `transforms.Normalize()`\n",
    "\n",
    "Multiple transformations can be chained by using `transforms.Compose`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize image to mean 0.5 and std 0.5\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's define the train and test dataset again, with the proper transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can load mini-batches of data from the dataset using `DataLoader`.\n",
    "\n",
    "Setting `shuffle=True` allows the batches to be sampled in a random order across different episodes. \n",
    "\n",
    "Why do we need it? $\\rightarrow$ Prevents converging into local optima and overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now look at one batch of data sampled from the `DataLoader`\n",
    "\n",
    "The input data shape would be: [batch_size, channel, height, width]. Here channel=1 because we are using grayscale images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(\"Input batch shape: \", images.shape)\n",
    "print(\"Output batch shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the sampled dataset (run the next cell several times to see random samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "idx = 0  # Change the index to see different images\n",
    "\n",
    "# Show some images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(7, 2.5))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(images[i+idx][0], cmap='gray')\n",
    "    axes[i].set_title(f\"label: {labels[i+idx]}\")\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the neural network structure\n",
    "\n",
    "For the MNIST task, it is sufficient to use a small, fully-connected neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=28*28, num_classes=10, hidden_size=128):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN().to(device)\n",
    "print(model) # Look at the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the loss function\n",
    "\n",
    "Here we are dealing with a classification problem with 10 classes (digits from 0 to 9), which loss function should we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Cross-entropy Loss**\n",
    "\n",
    "For one data pair $(x,y)$, the cross-entropy loss is calculated\n",
    "\n",
    "$$\n",
    "l_\\text{Cross-Entropy}(y,y') = - \\sum_{i=1}^{C} \\log \\frac{\\exp{y_i}}{\\sum_{c=1}^{C} \\exp{(y_{c})}} y'_{i},\n",
    "$$\n",
    "\n",
    "Here \n",
    "- $\\{1, \\dots, C=10 \\}$ class indices. \n",
    "- $y'$ is a one-hot vector, i.e. $y'_{i}=1$ if the ground truth label is class $i$. \n",
    "- $y$ is the output predicted by the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "l_\\text{Cross-Entropy}(y,y') = - \\sum_{i=1}^{C} \\log \\frac{\\exp{y_i}}{\\sum_{c=1}^{C} \\exp{(y_{c})}} y'_{i},\n",
    "$$\n",
    "\n",
    "- Note 1: The first part $\\exp{y_i}/\\sum_c\\exp{y_c}$ is a `Softmax` activation, mapping the unbounded outputs to probabilities between $[0,1]$.\n",
    "- Note 2: For the batched input, the loss is commonly averaged over the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define an optimizer\n",
    "\n",
    "We can choose from the common optimizers, see [`torch.optim` documentation](https://pytorch.org/docs/stable/optim.html):\n",
    "- Stochastic gradient descent ([SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)): `optim.SGD`\n",
    "- [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam): `optim.Adam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to change the optimizer and its hyperparameters\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs): # Loop through the dataset multiple epochs\n",
    "        for i, (images, labels) in enumerate(train_loader): # Loop through batches in the train loader\n",
    "            images, labels = images.to(device), labels.to(device) # Move data to device (GPU if available)\n",
    "            outputs = model(images) # Forward pass\n",
    "            loss = criterion(outputs, labels) # Compute loss\n",
    "\n",
    "            optimizer.zero_grad() # Prepare for backward pass\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update model parameters\n",
    "\n",
    "            if (i+1) % 400 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualize the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine a loader to allow for visualization of random test images\n",
    "random_test_loader = DataLoader(dataset=test_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "images, labels = next(iter(random_test_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs = model(images)\n",
    "_, predictions = torch.max(outputs, 1)\n",
    "\n",
    "# Show some images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(7, 2.5))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(images[i][0], cmap='gray')\n",
    "    axes[i].set_title(f\"label: {labels[i]} \\n pred: {predictions[i]}\")\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's next\n",
    "\n",
    "Change the hyperparameters of the network, training process, and observe what will happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "\n",
    "Try a different network structure, which one would you use?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
